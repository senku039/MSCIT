<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Reading Speed Test</title>
  <link rel="stylesheet" href="/theme.css">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
  <style>
    body { background: url('/IMAGES/kids.jpg') no-repeat center center/cover; font-family: Arial, sans-serif; padding: 20px; }
    .container { max-width: min(1260px, 96vw); margin-top: clamp(16px, 3vh, 44px); background: rgba(255,255,255,.95); padding: clamp(18px, 2.4vw, 36px); border-radius: 12px; box-shadow: 0 10px 24px rgba(0,0,0,.18); }
    #textToRead { height: clamp(240px, 38vh, 420px); overflow-y: auto; border: 1px solid #ccd6f3; border-radius: 10px; padding: 14px; margin-bottom: 18px; background: #f8fbff; }
    .camera-block { border: 1px solid #ccd6f3; border-radius: 12px; background: #f8fbff; padding: 12px; margin-bottom: 10px; }
    .video-shell { position: relative; width: 100%; max-height: 46vh; min-height: clamp(220px, 30vh, 360px); display: none; }
    video { width: 100%; height: 100%; object-fit: cover; border-radius: 10px; display: block; }
    #faceOverlay { position: absolute; inset: 0; width: 100%; height: 100%; border-radius: 10px; pointer-events: none; }
    #trackingHint { font-size: .88rem; color: #5f6b86; margin-top: 6px; display: none; }
  </style>
</head>
<body>
  <button class="global-back-btn" type="button" onclick="window.location.href='index.html'">← Back</button>
  <div class="container">
    <h1 class="text-center mb-3">Reading Speed Test</h1>
    <p class="text-muted">To prevent false high scores, the test validates minimum reading time and a quick comprehension check.</p>
    <div class="camera-block">
      <div id="videoShell" class="video-shell">
        <video id="webcam" autoplay playsinline muted></video>
        <canvas id="faceOverlay"></canvas>
      </div>
      <div id="trackingHint">Tip: keep your full face centered in the guide zone for accurate tracking.</div>
      <div class="d-flex gap-2 mt-2 mb-2">
        <button id="startCameraBtn" class="btn btn-outline-primary btn-sm">Start Camera Tracking</button>
        <button id="stopCameraBtn" class="btn btn-outline-secondary btn-sm" style="display:none;">Stop Camera</button>
      </div>
      <div id="cameraStatus" class="alert alert-warning py-2 mt-2" style="display:none;"></div>
      <div id="trackingPanel" class="alert alert-info py-2" style="display:none;"></div>
      <small id="testStateLabel" class="text-muted">State: idle</small>
    </div>

    <small class="text-muted d-block mb-2">Privacy note: this test uses <strong>video only</strong> for focus/face estimation. It does <strong>not</strong> capture audio.</small>
    <div class="mb-3">
      <p>Read the following text naturally:</p>
      <div id="textToRead"></div>
    </div>

    <div id="questionBlock" class="alert alert-light border" style="display:none;">
      <div id="questionText" class="fw-semibold mb-2"></div>
      <div id="questionOptions"></div>
      <button id="submitAnswerBtn" class="btn btn-outline-primary btn-sm mt-2" style="display:none;">Submit Answer</button>
    </div>

    <button id="startBtn" class="btn btn-primary w-100">Start Reading Test</button>
    <button id="stopBtn" class="btn btn-danger w-100 mt-3" style="display:none;">Stop Reading</button>
    <div id="result" class="mt-4 text-center" style="font-size:1.08em;"></div>
    <button id="finishTestBtn" class="btn btn-info w-100 mt-3" style="display:none;">Finish Test</button>
  </div>

  <script>
    const passages = [
      {
        text: "Maya loves visiting the library after school. She picks a new book every week and reads with her grandmother in the evening. Reading together helps her learn new words and understand stories better.",
        question: "Who reads with Maya in the evening?",
        options: ["Her teacher", "Her grandmother", "Her brother"],
        answer: "Her grandmother"
      },
      {
        text: "Arjun planted tomato seeds in a small garden behind his house. Every morning he watered the plants and checked for new leaves. After a few weeks, tiny green tomatoes appeared.",
        question: "What did Arjun plant?",
        options: ["Tomato seeds", "Rice seeds", "Rose flowers"],
        answer: "Tomato seeds"
      },
      {
        text: "The school science club built a small weather station. Students measured temperature, wind, and rainfall each day. They compared the data and learned how weather changes over time.",
        question: "What did students measure daily?",
        options: ["Only temperature", "Temperature, wind and rainfall", "Only rainfall"],
        answer: "Temperature, wind and rainfall"
      },
      {
        text: "On Sunday, Aisha and her brother cleaned their room. They sorted books, folded clothes, and arranged toys on shelves. Their room looked bright, neat, and easy to study in.",
        question: "What did they arrange on shelves?",
        options: ["Shoes", "Toys", "Food"],
        answer: "Toys"
      }
    ];

    const MAX_VALID_WPM = 420;
    const MIN_VALID_FOCUS_SECONDS = 5;
    const DETECT_SAMPLE_MS = 140;
    const AWAY_TRIGGER_MS = 500;
    const AWAY_GRACE_MS = 300;
    const MIN_FACE_AREA_RATIO = 0.008;
    const MIN_CONFIDENCE = 0.2;

    // State machine required for stable integration with the wider project.
    const STATE = { IDLE: 'idle', RUNNING: 'running', SUBMITTED: 'submitted', FINISHED: 'finished' };
    let testState = STATE.IDLE;

    let selectedPassage;
    let videoStream = null;
    let pendingMetrics = null;
    let submitLocked = false;

    // Single source of truth for timer.
    let runStartEpochMs = 0;
    let elapsedMs = 0;
    let timerInterval = null;

    // Detection engine + loop control.
    let faceDetector = null;
    let blazeModel = null;
    let detectionEngine = 'none';
    let detectionActive = false;
    let detectionRaf = null;
    let lastDetectionTick = 0;

    // Tracking metrics.
    let facePresenceMs = 0;
    let lookingAwayMs = 0;
    let continuousAwayDurationMs = 0;
    let maxContinuousAwayMs = 0;
    let unstableSamples = 0;
    let detectionSamples = 0;
    let stableFaceSamples = 0;
    let lookAwayAlerts = 0;
    let eyeMovementScore = 0;

    let smoothedCenter = null;
    let lastRawCenter = null;
    let recentConfidences = [];
    let detectorWarmupPromise = null;

    function randomPick(items) { return items[Math.floor(Math.random() * items.length)]; }

    function setState(next) {
      testState = next;
      document.getElementById('testStateLabel').textContent = `State: ${next}`;

      const startBtn = document.getElementById('startBtn');
      const stopBtn = document.getElementById('stopBtn');
      const finishBtn = document.getElementById('finishTestBtn');
      const submitBtn = document.getElementById('submitAnswerBtn');

      startBtn.disabled = next === STATE.RUNNING;
      startBtn.style.display = next === STATE.RUNNING ? 'none' : 'block';
      stopBtn.style.display = next === STATE.RUNNING ? 'block' : 'none';
      stopBtn.disabled = next !== STATE.RUNNING;
      submitBtn.disabled = next === STATE.FINISHED;

      if (next === STATE.SUBMITTED || next === STATE.FINISHED) {
        finishBtn.style.display = 'block';
      }
    }

    function loadPassage() {
      selectedPassage = randomPick(passages);
      document.getElementById('textToRead').innerText = selectedPassage.text;
      document.getElementById('questionBlock').style.display = 'none';
      document.getElementById('result').innerText = '';
    }

    function renderQuestion() {
      const block = document.getElementById('questionBlock');
      const optionsHost = document.getElementById('questionOptions');
      block.style.display = 'block';
      document.getElementById('questionText').textContent = selectedPassage.question;
      optionsHost.innerHTML = '';
      selectedPassage.options.forEach((opt, i) => {
        const id = `opt_${i}`;
        optionsHost.innerHTML += `<div class="form-check"><input class="form-check-input" type="radio" name="answer" id="${id}" value="${opt}"><label class="form-check-label" for="${id}">${opt}</label></div>`;
      });
      const submitBtn = document.getElementById('submitAnswerBtn');
      submitBtn.style.display = 'inline-block';
      submitBtn.disabled = false;
    }

    function updateStatus(type, message) {
      const cameraStatus = document.getElementById('cameraStatus');
      cameraStatus.style.display = 'block';
      cameraStatus.className = `alert alert-${type} py-2 mt-2`;
      cameraStatus.textContent = message;
    }

    function updateTrackingPanel() {
      const panel = document.getElementById('trackingPanel');
      panel.style.display = 'block';

      const elapsedSeconds = Math.max(elapsedMs / 1000, 1);
      const qualityRatio = Math.min(facePresenceMs / (elapsedMs || 1), 1);
      const qualityPct = Math.round(qualityRatio * 100);

      panel.innerHTML = `Face presence: <strong>${Math.round(facePresenceMs / 1000)}s</strong> | Looking away: <strong>${Math.round(lookingAwayMs / 1000)}s</strong> | Eye movement: <strong>${eyeMovementScore.toFixed(1)}</strong> | Tracking quality: <strong>${qualityPct}%</strong> | Run time: <strong>${elapsedSeconds.toFixed(1)}s</strong>`;
    }

    function resetMetrics() {
      elapsedMs = 0;
      facePresenceMs = 0;
      lookingAwayMs = 0;
      continuousAwayDurationMs = 0;
      maxContinuousAwayMs = 0;
      unstableSamples = 0;
      detectionSamples = 0;
      stableFaceSamples = 0;
      lookAwayAlerts = 0;
      eyeMovementScore = 0;
      submitLocked = false;
      smoothedCenter = null;
      lastRawCenter = null;
      recentConfidences = [];
      pendingMetrics = null;
    }

    function startTimer() {
      stopTimer();
      runStartEpochMs = Date.now();
      timerInterval = setInterval(() => {
        if (testState !== STATE.RUNNING) return;
        elapsedMs = Date.now() - runStartEpochMs;
        updateTrackingPanel();
      }, 200);
    }

    function stopTimer() {
      if (timerInterval) {
        clearInterval(timerInterval);
        timerInterval = null;
      }
    }

    function drawOverlay(face, roi, stable = true) {
      const video = document.getElementById('webcam');
      const canvas = document.getElementById('faceOverlay');
      const ctx = canvas.getContext('2d');
      const width = video.videoWidth || 1;
      const height = video.videoHeight || 1;
      if (canvas.width !== width || canvas.height !== height) {
        canvas.width = width;
        canvas.height = height;
      }

      ctx.clearRect(0, 0, width, height);

      // ROI box used directly in logic (not just for visuals).
      ctx.strokeStyle = 'rgba(21,111,247,0.9)';
      ctx.lineWidth = 2;
      ctx.strokeRect(roi.x, roi.y, roi.width, roi.height);

      if (face) {
        ctx.strokeStyle = stable ? 'rgba(27,180,103,0.95)' : 'rgba(220,53,69,0.95)';
        ctx.lineWidth = 3;
        ctx.strokeRect(face.x, face.y, face.width, face.height);
        ctx.fillStyle = stable ? 'rgba(27,180,103,0.14)' : 'rgba(220,53,69,0.14)';
        ctx.fillRect(face.x, face.y, face.width, face.height);
      }
    }

    function getRoi(video) {
      const w = video.videoWidth || 1;
      const h = video.videoHeight || 1;
      const roiW = w * 0.78;
      const roiH = h * 0.82;
      return {
        x: (w - roiW) / 2,
        y: (h - roiH) / 2,
        width: roiW,
        height: roiH,
      };
    }

    function toFaceObject(face) {
      if (face.boundingBox) {
        const box = face.boundingBox;
        const conf = typeof face.confidence === 'number' ? face.confidence : 0.9;
        return { x: box.x, y: box.y, width: box.width, height: box.height, confidence: conf };
      }
      const [x1, y1] = face.topLeft || [0, 0];
      const [x2, y2] = face.bottomRight || [0, 0];
      const p = Array.isArray(face.probability) ? face.probability[0] : face.probability;
      return {
        x: Number(x1),
        y: Number(y1),
        width: Math.max(Number(x2) - Number(x1), 1),
        height: Math.max(Number(y2) - Number(y1), 1),
        confidence: Number.isFinite(p) ? Number(p) : 0.85,
      };
    }

    function smoothCenter(rawCenter) {
      if (!smoothedCenter) {
        smoothedCenter = { ...rawCenter };
        return smoothedCenter;
      }
      const alpha = 0.28;
      smoothedCenter = {
        x: (alpha * rawCenter.x) + ((1 - alpha) * smoothedCenter.x),
        y: (alpha * rawCenter.y) + ((1 - alpha) * smoothedCenter.y),
      };
      return smoothedCenter;
    }

    function averageConfidence(next) {
      recentConfidences.push(next);
      if (recentConfidences.length > 6) recentConfidences.shift();
      return recentConfidences.reduce((acc, c) => acc + c, 0) / recentConfidences.length;
    }

    async function loadExternalScript(src) {
      return new Promise((resolve, reject) => {
        const existing = document.querySelector(`script[data-src="${src}"]`);
        if (existing) {
          if (existing.dataset.loaded === '1') return resolve();
          existing.addEventListener('load', () => resolve(), { once: true });
          existing.addEventListener('error', () => reject(new Error(src)), { once: true });
          return;
        }
        const script = document.createElement('script');
        script.src = src;
        script.async = true;
        script.dataset.src = src;
        script.onload = () => { script.dataset.loaded = '1'; resolve(); };
        script.onerror = () => reject(new Error(src));
        document.head.appendChild(script);
      });
    }

    async function initDetectionEngine() {
      if (detectionEngine !== 'none') return true;
      if (detectorWarmupPromise) return detectorWarmupPromise;

      detectorWarmupPromise = (async () => {
        if ('FaceDetector' in window) {
          try {
            faceDetector = new window.FaceDetector({ fastMode: true, maxDetectedFaces: 1 });
            detectionEngine = 'shape';
            return true;
          } catch (_error) {
            detectionEngine = 'none';
          }
        }
        try {
          await loadExternalScript('https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.20.0/dist/tf.min.js');
          await loadExternalScript('https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface@0.0.7/dist/blazeface.min.js');
          blazeModel = await window.blazeface.load();
          detectionEngine = 'blazeface';
          return true;
        } catch (_error) {
          detectionEngine = 'none';
          return false;
        }
      })();
      return detectorWarmupPromise;
    }

    async function detectFace(video) {
      if (detectionEngine === 'shape' && faceDetector) {
        const faces = await faceDetector.detect(video);
        return faces.length ? toFaceObject(faces[0]) : null;
      }
      if (detectionEngine === 'blazeface' && blazeModel) {
        const faces = await blazeModel.estimateFaces(video, false);
        return faces.length ? toFaceObject(faces[0]) : null;
      }
      return null;
    }

    function stopDetection() {
      detectionActive = false;
      if (detectionRaf) {
        cancelAnimationFrame(detectionRaf);
        detectionRaf = null;
      }
    }

    async function detectionTick(timestamp) {
      if (!detectionActive || testState !== STATE.RUNNING) return;
      const video = document.getElementById('webcam');
      const roi = getRoi(video);

      if (!lastDetectionTick) lastDetectionTick = timestamp;
      const delta = timestamp - lastDetectionTick;
      if (delta < DETECT_SAMPLE_MS) {
        detectionRaf = requestAnimationFrame(detectionTick);
        return;
      }
      lastDetectionTick = timestamp;

      try {
        const face = await detectFace(video);
        const frameArea = Math.max((video.videoWidth || 1) * (video.videoHeight || 1), 1);
        detectionSamples += 1;

        let awayNow = true;
        if (face) {
          const center = { x: face.x + (face.width / 2), y: face.y + (face.height / 2) };
          const smooth = smoothCenter(center);
          const confAvg = averageConfidence(face.confidence);
          const areaRatio = (face.width * face.height) / frameArea;
          const roiMarginX = roi.width * 0.08;
          const roiMarginY = roi.height * 0.08;
          const inRoi = smooth.x >= (roi.x - roiMarginX) && smooth.x <= (roi.x + roi.width + roiMarginX)
            && smooth.y >= (roi.y - roiMarginY) && smooth.y <= (roi.y + roi.height + roiMarginY);
          const largeEnough = areaRatio >= MIN_FACE_AREA_RATIO;
          const confGood = confAvg >= MIN_CONFIDENCE;

          awayNow = !(inRoi && largeEnough && confGood);

          // Count face presence whenever a face is detected; away-state is tracked separately.
          facePresenceMs += delta;
          if (!awayNow) {
            stableFaceSamples += 1;
          } else {
            unstableSamples += 1;
          }

          if (lastRawCenter) {
            const dx = Math.abs(center.x - lastRawCenter.x);
            const dy = Math.abs(center.y - lastRawCenter.y);
            eyeMovementScore += Math.min(((dx + dy) / Math.max(face.width + face.height, 1)) * 100, 10);
          }
          lastRawCenter = center;

          drawOverlay(face, roi, !awayNow);
        } else {
          awayNow = true;
          unstableSamples += 1;
          drawOverlay(null, roi, false);
        }

        if (awayNow) {
          continuousAwayDurationMs += delta;
          maxContinuousAwayMs = Math.max(maxContinuousAwayMs, continuousAwayDurationMs);

          // Ignore short drops < 300ms to prevent flicker penalties.
          if (continuousAwayDurationMs > AWAY_GRACE_MS) {
            lookingAwayMs += delta;
          }
          if (continuousAwayDurationMs > AWAY_TRIGGER_MS && (continuousAwayDurationMs - delta) <= AWAY_TRIGGER_MS) {
            lookAwayAlerts += 1;
            updateStatus('danger', 'Face detected but not centered. Please move into the blue guide box.');
          }
        } else {
          if (continuousAwayDurationMs > AWAY_TRIGGER_MS / 2) {
            updateStatus('success', 'Face stable. Continue reading naturally.');
          }
          continuousAwayDurationMs = 0;
        }

        updateTrackingPanel();
      } catch (_error) {
        updateStatus('warning', 'Temporary face detection issue. Trying to recover…');
      }

      detectionRaf = requestAnimationFrame(detectionTick);
    }

    async function startDetection() {
      if (testState !== STATE.RUNNING || detectionActive) return;
      const video = document.getElementById('webcam');
      if (video.readyState < 2) return;

      const ok = await initDetectionEngine();
      if (!ok) {
        updateStatus('warning', 'Face detection model unavailable. Verify internet/browser support and retry camera.');
        return;
      }

      updateStatus('success', `Camera active. ${detectionEngine === 'shape' ? 'Native' : 'ML'} face tracking running.`);
      detectionActive = true;
      lastDetectionTick = 0;
      detectionRaf = requestAnimationFrame(detectionTick);
    }

    async function ensureCameraReady() {
      if (videoStream) return true;

      const video = document.getElementById('webcam');
      const shell = document.getElementById('videoShell');
      const startCamBtn = document.getElementById('startCameraBtn');
      const stopCamBtn = document.getElementById('stopCameraBtn');

      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        updateStatus('warning', 'Camera API is not supported in this browser.');
        return false;
      }

      try {
        videoStream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: 'user', width: { ideal: 1280 }, height: { ideal: 720 } },
          audio: false,
        });
        video.srcObject = videoStream;
        shell.style.display = 'block';
        await video.play();

        document.getElementById('trackingHint').style.display = 'block';
        startCamBtn.style.display = 'none';
        stopCamBtn.style.display = 'inline-block';
        updateTrackingPanel();
        return true;
      } catch (_error) {
        updateStatus('warning', 'Camera permission denied or unavailable.');
        return false;
      }
    }

    function cleanupCamera() {
      stopDetection();
      if (videoStream) {
        videoStream.getTracks().forEach((track) => track.stop());
        videoStream = null;
      }
      const video = document.getElementById('webcam');
      video.srcObject = null;
      document.getElementById('videoShell').style.display = 'none';
      document.getElementById('trackingHint').style.display = 'none';
      document.getElementById('startCameraBtn').style.display = 'inline-block';
      document.getElementById('stopCameraBtn').style.display = 'none';

      const canvas = document.getElementById('faceOverlay');
      const ctx = canvas.getContext('2d');
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      // Release detector references to avoid leaks between test sessions.
      faceDetector = null;
      blazeModel = null;
      detectionEngine = 'none';
    }

    async function startTestFlow() {
      if (testState === STATE.RUNNING) return;
      resetMetrics();
      setState(STATE.RUNNING);
      document.getElementById('result').innerText = '';
      document.getElementById('finishTestBtn').style.display = 'none';
      document.getElementById('questionBlock').style.display = 'none';

      // Start test immediately; camera setup runs in background so permission prompts do not block test start.
      startTimer();
      updateStatus('info', 'Reading test started. Camera tracking will attach automatically when ready.');
      ensureCameraReady()
        .then(async (cameraOk) => {
          if (cameraOk && testState === STATE.RUNNING) {
            await startDetection();
          }
        })
        .catch(() => {
          updateStatus('warning', 'Camera setup is delayed. Test continues and you can retry camera tracking.');
        });
    }

    function stopRunningPhase() {
      if (testState !== STATE.RUNNING) return;
      stopTimer();
      stopDetection();
      elapsedMs = Date.now() - runStartEpochMs;
    }

    function buildTrackingQuality(metrics) {
      const total = Math.max(metrics.elapsedSeconds, 1);
      const presenceRatio = metrics.faceVisibleSeconds / total;
      const awayPenalty = Math.min(metrics.maxContinuousAwaySeconds / total, 1) * 0.25;
      const unstablePenalty = Math.min(metrics.unstableRate, 1) * 0.2;
      return Math.max(0, Math.min(1, presenceRatio - awayPenalty - unstablePenalty));
    }

    function finalizeSubmission() {
      const wordCount = document.getElementById('textToRead').innerText.trim().split(/\s+/).filter(Boolean).length;
      const elapsedSeconds = Math.max(elapsedMs / 1000, 1);
      const minExpectedSeconds = (wordCount / MAX_VALID_WPM) * 60;

      pendingMetrics = {
        elapsedSeconds,
        wordCount,
        minExpectedSeconds,
        focusTime: Math.round(elapsedMs / 1000),
        faceVisibleSeconds: Math.round(facePresenceMs / 1000),
        lookAwaySeconds: Math.round(lookingAwayMs / 1000),
        maxContinuousAwaySeconds: Math.round(maxContinuousAwayMs / 1000),
        eyeMovementScore,
        lookAwayAlerts,
        detectionSamples,
        stableFaceSamples,
        unstableRate: detectionSamples ? ((detectionSamples - stableFaceSamples) / detectionSamples) : 0,
      };
      pendingMetrics.trackingQuality = buildTrackingQuality(pendingMetrics);

      renderQuestion();
      document.getElementById('result').innerText = 'Submitted. Answer the comprehension question to complete validation.';
      setState(STATE.SUBMITTED);
    }

    document.getElementById('startCameraBtn').addEventListener('click', async () => {
      updateStatus('info', 'Preparing camera and face detector...');
      await initDetectionEngine();
      const ok = await ensureCameraReady();
      if (ok && testState === STATE.RUNNING) {
        await startDetection();
      }
    });

    document.getElementById('stopCameraBtn').addEventListener('click', () => {
      cleanupCamera();
      updateStatus('warning', 'Camera stopped. Tracking paused until camera restarts.');
    });

    document.getElementById('startBtn').addEventListener('click', async () => {
      submitLocked = false;
      await startTestFlow();
    });

    document.getElementById('stopBtn').addEventListener('click', () => {
      if (testState !== STATE.RUNNING || submitLocked) return;
      submitLocked = true;
      stopRunningPhase();
      finalizeSubmission();
    });

    document.getElementById('submitAnswerBtn').addEventListener('click', () => {
      if (testState !== STATE.SUBMITTED || !pendingMetrics) return;
      const chosen = document.querySelector('input[name="answer"]:checked');
      if (!chosen) {
        document.getElementById('result').innerText = 'Please select an answer before finishing submission.';
        return;
      }

      const correct = chosen.value === selectedPassage.answer;
      const rawWpm = (pendingMetrics.wordCount / pendingMetrics.elapsedSeconds) * 60;
      const wordsPerMinute = Math.min(rawWpm, MAX_VALID_WPM);

      // Reliability only indicates data quality, never user performance.
      const dataComplete = pendingMetrics.elapsedSeconds >= 1 && pendingMetrics.wordCount >= 10;
      const cameraUsable = pendingMetrics.detectionSamples === 0
        ? false
        : ((pendingMetrics.faceVisibleSeconds / Math.max(pendingMetrics.elapsedSeconds, 1)) >= 0.35);
      const qualityTag = dataComplete && (cameraUsable || pendingMetrics.focusTime >= MIN_VALID_FOCUS_SECONDS)
        ? 'usable'
        : 'needs_review';

      const comprehensionAccuracy = correct ? 100 : 0;
      document.getElementById('result').innerText = `Reading score recorded: ${wordsPerMinute.toFixed(2)} WPM | Comprehension: ${comprehensionAccuracy}% | Face Presence: ${pendingMetrics.faceVisibleSeconds}s | Looking Away: ${pendingMetrics.lookAwaySeconds}s | Tracking Quality: ${(pendingMetrics.trackingQuality * 100).toFixed(0)}%`;
      sessionStorage.setItem('reading_speed_score', wordsPerMinute.toFixed(2));
      sessionStorage.setItem('reading_speed_reliability', qualityTag);
      sessionStorage.setItem('reading_comprehension_accuracy', String(comprehensionAccuracy));
      sessionStorage.setItem('camera_reliability', (pendingMetrics.trackingQuality * 100).toFixed(0));
      sessionStorage.setItem('attention_stability', (Math.max(0, 100 - pendingMetrics.lookAwaySeconds * 8)).toFixed(2));
      sessionStorage.setItem('movement_variability', pendingMetrics.eyeMovementScore.toFixed(2));

      sessionStorage.setItem('focus_time', String(pendingMetrics.focusTime));
      sessionStorage.setItem('face_presence_time', String(pendingMetrics.faceVisibleSeconds));
      sessionStorage.setItem('eye_movement_index', pendingMetrics.eyeMovementScore.toFixed(2));
      sessionStorage.setItem('looking_away_seconds', String(pendingMetrics.lookAwaySeconds));
      sessionStorage.setItem('tracking_quality', (pendingMetrics.trackingQuality * 100).toFixed(0));

      document.getElementById('submitAnswerBtn').disabled = true;
      updateStatus('success', 'Submission completed. You can finish or restart the test.');
      setState(STATE.FINISHED);
    });

    document.getElementById('finishTestBtn').addEventListener('click', () => {
      stopRunningPhase();
      cleanupCamera();
      setState(STATE.FINISHED);
      window.location.href = '/dyslexia-prediction';
    });

    document.addEventListener('DOMContentLoaded', () => {
      loadPassage();
      setState(STATE.IDLE);
      updateTrackingPanel();
      // Warm detector before test starts to avoid 5-10s startup delay.
      setTimeout(() => { initDetectionEngine().catch(() => {}); }, 250);
    });
  </script>
</body>
</html>
